{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "saved-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assisted-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excessive-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = models.alexnet(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inclusive-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alive-exhibit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 186\n",
      "Test set size: 144\n",
      "Train Labels size: 186\n",
      "Train Labels size: 144\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "{1: 60, 2: 88, 3: 38}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "imgs_train = []\n",
    "imgs_test = []\n",
    "imgs_train_paths = []\n",
    "labels_train = []\n",
    "labels_test = []\n",
    "for img in glob.glob(\"C:/Users/etuna/Desktop/hw3/dataset/dataset/training/*\"):\n",
    "    imgs_train_paths.append(img)\n",
    "    n= cv2.imread(img)\n",
    "    imgs_train.append(n)\n",
    "    \n",
    "for img in glob.glob(\"C:/Users/etuna/Desktop/hw3/dataset/dataset/test/*\"):\n",
    "    n= cv2.imread(img)\n",
    "    imgs_test.append(n)\n",
    "    \n",
    "with open('C:/Users/etuna/Desktop/hw3/dataset/dataset/training_labels.txt', 'r') as file:\n",
    "    labelStr = file.read().replace('\\n', '')\n",
    "    labels_train = list(map(int,labelStr))\n",
    "    \n",
    "with open('C:/Users/etuna/Desktop/hw3/dataset/dataset/test_labels.txt', 'r') as file:\n",
    "    labelStr = file.read().replace('\\n', '')\n",
    "    labels_test = list(map(int,labelStr))\n",
    "    \n",
    "print(\"Train set size:\",len(imgs_train))\n",
    "print(\"Test set size:\",len(imgs_test))\n",
    "print(\"Train Labels size:\", len(labels_train))\n",
    "print(\"Train Labels size:\", len(labels_test))\n",
    "print(labels_train)\n",
    "\n",
    "label_dict = {}\n",
    "for l in labels_train:\n",
    "    if not l in label_dict:\n",
    "        label_dict[l] = 1\n",
    "    else:\n",
    "        label_dict[l] += 1\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fresh-begin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minc = min(label_dict,key=label_dict.get)\n",
    "label_dict[minc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "banned-specification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr1.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr10.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr100.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr101.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr102.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr103.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr104.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr105.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr106.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr107.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr108.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr109.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr11.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr110.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr111.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr112.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr113.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr114.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr115.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr116.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr117.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr118.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr119.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr12.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr120.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr121.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr122.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr123.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr124.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr125.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr126.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr127.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr128.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr129.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr13.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr130.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr131.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr132.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr133.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr134.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr135.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr136.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr137.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr138.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr139.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr14.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr140.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr141.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr142.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr143.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr144.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr145.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr146.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr147.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr148.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr149.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr15.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr150.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr151.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr152.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr153.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr154.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr155.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr156.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr157.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr158.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr159.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr16.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr160.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr161.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr162.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr163.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr164.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr165.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr166.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr167.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr168.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr169.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr17.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr170.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr171.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr172.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr173.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr174.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr175.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr176.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr177.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr178.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr179.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr18.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr180.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr181.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr182.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr183.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr184.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr185.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr186.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr19.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr2.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr20.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr21.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr22.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr23.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr24.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr25.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr26.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr27.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr28.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr29.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr3.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr30.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr31.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr32.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr33.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr34.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr35.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr36.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr37.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr38.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr39.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr4.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr40.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr41.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr42.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr43.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr44.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr45.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr46.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr47.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr48.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr49.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr5.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr50.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr51.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr52.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr53.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr54.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr55.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr56.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr57.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr58.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr59.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr6.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr60.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr61.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr62.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr63.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr64.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr65.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr66.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr67.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr68.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr69.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr7.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr70.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr71.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr72.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr73.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr74.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr75.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr76.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr77.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr78.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr79.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr8.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr80.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr81.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr82.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr83.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr84.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr85.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr86.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr87.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr88.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr89.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr9.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr90.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr91.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr92.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr93.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr94.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr95.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr96.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr97.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr98.jpg',\n",
       " 'C:/Users/etuna/Desktop/hw3/dataset/dataset/training\\\\tr99.jpg']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "identical-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tr1.jpg'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train_paths[0].split('\\\\')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sixth-strategy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "{1: 60, 2: 88, 3: 38}\n"
     ]
    }
   ],
   "source": [
    "print(str(len(imgs_train)))\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "younger-shore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valids: 12 17 7\n"
     ]
    }
   ],
   "source": [
    "one_valid = int(label_dict[1]*0.2)\n",
    "two_valid = int(label_dict[2]*0.2)\n",
    "three_valid = int(label_dict[3]*0.2)\n",
    "print(\"valids:\",one_valid,two_valid,three_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "revised-waste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "tr10.jpg\n"
     ]
    }
   ],
   "source": [
    "print(str(len(imgs_train)))\n",
    "print(imgs_train_paths[1].split(\"\\\\\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "enabling-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDataset():\n",
    "    train_path = \"C:/Users/etuna/Desktop/hw3/dataset/dataset/dir/train/\"\n",
    "    valid_path = \"C:/Users/etuna/Desktop/hw3/dataset/dataset/dir/valid/\"\n",
    "    test_path = \"C:/Users/etuna/Desktop/hw3/dataset/dataset/dir/test/\"\n",
    "    one_valid = int(label_dict[1]*0.2)\n",
    "    two_valid = int(label_dict[2]*0.2)\n",
    "    three_valid = int(label_dict[3]*0.2)\n",
    "    print(\"valids:\",one_valid,two_valid,three_valid)\n",
    "    \n",
    "    t_path = \"C:/Users/etuna/Desktop\\hw3/dataset/dataset/dir/\"\n",
    "    ## save to related dirs\n",
    "\n",
    "    for i, img in enumerate(imgs_train):\n",
    "        if labels_train[i] == 1:\n",
    "            if one_valid > 0:\n",
    "                cv2.imwrite(valid_path+\"1/\"+imgs_train_paths[i].split(\"\\\\\")[1], img)\n",
    "                one_valid -= 1\n",
    "            else:\n",
    "                cv2.imwrite(train_path+\"1/\"+imgs_train_paths[i].split(\"\\\\\")[1], img)\n",
    "        elif labels_train[i] == 2:\n",
    "            if two_valid > 0:\n",
    "                cv2.imwrite(valid_path+\"2/\"+imgs_train_paths[i].split(\"\\\\\")[1], img)\n",
    "                two_valid -= 1\n",
    "            else:\n",
    "                cv2.imwrite(train_path+\"2/\"+imgs_train_paths[i].split(\"\\\\\")[1], img)\n",
    "        else:\n",
    "            if three_valid > 0:\n",
    "                cv2.imwrite(valid_path+\"3/\"+imgs_train_paths[i].split(\"\\\\\")[1], img)\n",
    "                three_valid -= 1\n",
    "            else:\n",
    "                cv2.imwrite(train_path+\"3/\"+imgs_train_paths[i].split(\"\\\\\")[1], img)\n",
    "\n",
    "    for i, img in enumerate(imgs_test):\n",
    "        if labels_test[i] == 1:\n",
    "            cv2.imwrite(test_path+\"1/\"+imgs_test_pathsb[i], img)\n",
    "        elif labels_test[i] == 2:\n",
    "            cv2.imwrite(test_path+\"2/\"+imgs_test_pathsb[i], img)\n",
    "        else:\n",
    "            cv2.imwrite(test_path+\"3/\"+imgs_test_pathsb[i], img)\n",
    "    print(\"Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "living-injury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valids: 12 17 7\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "processDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "italian-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceSets(imgs_trainp, labels_trainp):\n",
    "    train_balance_path = \"C:/Users/etuna/Desktop/hw3/dataset/dataset/balanced/training_balanced/\"\n",
    "    valid_balance_path = \"C:/Users/etuna/Desktop/hw3/dataset/dataset/balanced/valid_balanced/\"\n",
    "    label_dict = {}\n",
    "    for l in labels_train:\n",
    "        if not l in label_dict:\n",
    "            label_dict[l] = 1\n",
    "        else:\n",
    "            label_dict[l] += 1\n",
    "    print(label_dict)\n",
    "    minc = min(label_dict,key=label_dict.get)\n",
    "    print(str(minc)+\":\"+str(label_dict[minc]))\n",
    "    \n",
    "    balance_dict = {}\n",
    "    train_labelStr= \"\"\n",
    "    valid_labelStr= \"\"\n",
    "    for i, img in enumerate(imgs_trainp):\n",
    "        if not labels_trainp[i] in balance_dict:\n",
    "            cv2.imwrite(train_balance_path+imgs_train_paths[i].split('\\\\')[1], img)\n",
    "            train_labelStr += str(labels_trainp[i])\n",
    "            balance_dict[labels_trainp[i]] = 1\n",
    "        else:\n",
    "            if balance_dict[labels_trainp[i]] < label_dict[minc]:\n",
    "                cv2.imwrite(train_balance_path+imgs_train_paths[i].split('\\\\')[1], img)\n",
    "                balance_dict[labels_trainp[i]] += 1\n",
    "                train_labelStr += str(labels_trainp[i])\n",
    "            else: # save as validation\n",
    "                cv2.imwrite(valid_balance_path+imgs_train_paths[i].split('\\\\')[1], img)\n",
    "                valid_labelStr += str(labels_trainp[i])\n",
    "                continue\n",
    "    with open(\"C:/Users/etuna/Desktop/hw3/dataset/dataset/balanced/training_balanced_labels\", \"w\") as text_file:\n",
    "        text_file.write(train_labelStr)\n",
    "    with open(\"C:/Users/etuna/Desktop/hw3/dataset/dataset/balanced/valid_balanced_labels\", \"w\") as text_file:\n",
    "        text_file.write(valid_labelStr)\n",
    "    print(balance_dict)\n",
    "    print(train_labelStr)\n",
    "    print(valid_labelStr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "nominated-cambridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 60, 2: 88, 3: 38}\n",
      "3:38\n",
      "{1: 38, 2: 38, 3: 38}\n",
      "111111111111111111111111111111111111112222222222222222222222222222222222222233333333333333333333333333333333333333\n",
      "111111111111111111111122222222222222222222222222222222222222222222222222\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "imgs_traincopy= copy.deepcopy(imgs_train)\n",
    "labels_traincopy= copy.deepcopy(labels_train)\n",
    "balanceSets(imgs_traincopy, labels_traincopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "marked-doubt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "facial-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.classifier[ 6 ] = nn.Linear( in_features = 4096, out_features = 3, bias = True )\n",
    "model_conv = model_conv.to(device) # use the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "certified-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "professional-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_conv = optim.SGD(model_conv.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR( optimizer_conv, step_size=30, gamma= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "analyzed-vault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "72\n",
      "144\n",
      "['tr1.jpg', 'tr10.jpg', 'tr100.jpg', 'tr101.jpg', 'tr102.jpg', 'tr103.jpg', 'tr104.jpg', 'tr105.jpg', 'tr106.jpg', 'tr107.jpg', 'tr108.jpg', 'tr109.jpg', 'tr11.jpg', 'tr110.jpg', 'tr111.jpg', 'tr112.jpg', 'tr113.jpg', 'tr114.jpg', 'tr115.jpg', 'tr116.jpg', 'tr117.jpg', 'tr118.jpg', 'tr119.jpg', 'tr12.jpg', 'tr120.jpg', 'tr121.jpg', 'tr122.jpg', 'tr123.jpg', 'tr124.jpg', 'tr125.jpg', 'tr126.jpg', 'tr127.jpg', 'tr128.jpg', 'tr129.jpg', 'tr13.jpg', 'tr130.jpg', 'tr131.jpg', 'tr132.jpg', 'tr153.jpg', 'tr154.jpg', 'tr155.jpg', 'tr156.jpg', 'tr157.jpg', 'tr158.jpg', 'tr159.jpg', 'tr16.jpg', 'tr160.jpg', 'tr161.jpg', 'tr162.jpg', 'tr163.jpg', 'tr164.jpg', 'tr165.jpg', 'tr166.jpg', 'tr167.jpg', 'tr168.jpg', 'tr169.jpg', 'tr17.jpg', 'tr170.jpg', 'tr171.jpg', 'tr172.jpg', 'tr173.jpg', 'tr174.jpg', 'tr175.jpg', 'tr176.jpg', 'tr177.jpg', 'tr178.jpg', 'tr179.jpg', 'tr18.jpg', 'tr180.jpg', 'tr181.jpg', 'tr182.jpg', 'tr183.jpg', 'tr184.jpg', 'tr185.jpg', 'tr186.jpg', 'tr19.jpg', 'tr65.jpg', 'tr66.jpg', 'tr67.jpg', 'tr68.jpg', 'tr69.jpg', 'tr7.jpg', 'tr70.jpg', 'tr71.jpg', 'tr72.jpg', 'tr73.jpg', 'tr74.jpg', 'tr75.jpg', 'tr76.jpg', 'tr77.jpg', 'tr78.jpg', 'tr79.jpg', 'tr8.jpg', 'tr80.jpg', 'tr81.jpg', 'tr82.jpg', 'tr83.jpg', 'tr84.jpg', 'tr85.jpg', 'tr86.jpg', 'tr87.jpg', 'tr88.jpg', 'tr89.jpg', 'tr9.jpg', 'tr90.jpg', 'tr91.jpg', 'tr92.jpg', 'tr93.jpg', 'tr94.jpg', 'tr95.jpg', 'tr96.jpg', 'tr97.jpg', 'tr98.jpg', 'tr99.jpg']\n",
      "---\n",
      "['tr133.jpg', 'tr134.jpg', 'tr135.jpg', 'tr136.jpg', 'tr137.jpg', 'tr138.jpg', 'tr139.jpg', 'tr14.jpg', 'tr140.jpg', 'tr141.jpg', 'tr142.jpg', 'tr143.jpg', 'tr144.jpg', 'tr145.jpg', 'tr146.jpg', 'tr147.jpg', 'tr148.jpg', 'tr149.jpg', 'tr15.jpg', 'tr150.jpg', 'tr151.jpg', 'tr152.jpg', 'tr2.jpg', 'tr20.jpg', 'tr21.jpg', 'tr22.jpg', 'tr23.jpg', 'tr24.jpg', 'tr25.jpg', 'tr26.jpg', 'tr27.jpg', 'tr28.jpg', 'tr29.jpg', 'tr3.jpg', 'tr30.jpg', 'tr31.jpg', 'tr32.jpg', 'tr33.jpg', 'tr34.jpg', 'tr35.jpg', 'tr36.jpg', 'tr37.jpg', 'tr38.jpg', 'tr39.jpg', 'tr4.jpg', 'tr40.jpg', 'tr41.jpg', 'tr42.jpg', 'tr43.jpg', 'tr44.jpg', 'tr45.jpg', 'tr46.jpg', 'tr47.jpg', 'tr48.jpg', 'tr49.jpg', 'tr5.jpg', 'tr50.jpg', 'tr51.jpg', 'tr52.jpg', 'tr53.jpg', 'tr54.jpg', 'tr55.jpg', 'tr56.jpg', 'tr57.jpg', 'tr58.jpg', 'tr59.jpg', 'tr6.jpg', 'tr60.jpg', 'tr61.jpg', 'tr62.jpg', 'tr63.jpg', 'tr64.jpg']\n",
      "---\n",
      "['ts1.jpg', 'ts10.jpg', 'ts100.jpg', 'ts101.jpg', 'ts102.jpg', 'ts103.jpg', 'ts104.jpg', 'ts105.jpg', 'ts106.jpg', 'ts107.jpg', 'ts108.jpg', 'ts109.jpg', 'ts11.jpg', 'ts110.jpg', 'ts111.jpg', 'ts112.jpg', 'ts113.jpg', 'ts114.jpg', 'ts115.jpg', 'ts116.jpg', 'ts117.jpg', 'ts118.jpg', 'ts119.jpg', 'ts12.jpg', 'ts120.jpg', 'ts121.jpg', 'ts122.jpg', 'ts123.jpg', 'ts124.jpg', 'ts125.jpg', 'ts126.jpg', 'ts127.jpg', 'ts128.jpg', 'ts129.jpg', 'ts13.jpg', 'ts130.jpg', 'ts131.jpg', 'ts132.jpg', 'ts133.jpg', 'ts134.jpg', 'ts135.jpg', 'ts136.jpg', 'ts137.jpg', 'ts138.jpg', 'ts139.jpg', 'ts14.jpg', 'ts140.jpg', 'ts141.jpg', 'ts142.jpg', 'ts143.jpg', 'ts144.jpg', 'ts15.jpg', 'ts16.jpg', 'ts17.jpg', 'ts18.jpg', 'ts19.jpg', 'ts2.jpg', 'ts20.jpg', 'ts21.jpg', 'ts22.jpg', 'ts23.jpg', 'ts24.jpg', 'ts25.jpg', 'ts26.jpg', 'ts27.jpg', 'ts28.jpg', 'ts29.jpg', 'ts3.jpg', 'ts30.jpg', 'ts31.jpg', 'ts32.jpg', 'ts33.jpg', 'ts34.jpg', 'ts35.jpg', 'ts36.jpg', 'ts37.jpg', 'ts38.jpg', 'ts39.jpg', 'ts4.jpg', 'ts40.jpg', 'ts41.jpg', 'ts42.jpg', 'ts43.jpg', 'ts44.jpg', 'ts45.jpg', 'ts46.jpg', 'ts47.jpg', 'ts48.jpg', 'ts49.jpg', 'ts5.jpg', 'ts50.jpg', 'ts51.jpg', 'ts52.jpg', 'ts53.jpg', 'ts54.jpg', 'ts55.jpg', 'ts56.jpg', 'ts57.jpg', 'ts58.jpg', 'ts59.jpg', 'ts6.jpg', 'ts60.jpg', 'ts61.jpg', 'ts62.jpg', 'ts63.jpg', 'ts64.jpg', 'ts65.jpg', 'ts66.jpg', 'ts67.jpg', 'ts68.jpg', 'ts69.jpg', 'ts7.jpg', 'ts70.jpg', 'ts71.jpg', 'ts72.jpg', 'ts73.jpg', 'ts74.jpg', 'ts75.jpg', 'ts76.jpg', 'ts77.jpg', 'ts78.jpg', 'ts79.jpg', 'ts8.jpg', 'ts80.jpg', 'ts81.jpg', 'ts82.jpg', 'ts83.jpg', 'ts84.jpg', 'ts85.jpg', 'ts86.jpg', 'ts87.jpg', 'ts88.jpg', 'ts89.jpg', 'ts9.jpg', 'ts90.jpg', 'ts91.jpg', 'ts92.jpg', 'ts93.jpg', 'ts94.jpg', 'ts95.jpg', 'ts96.jpg', 'ts97.jpg', 'ts98.jpg', 'ts99.jpg']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "img_train_balanced = []\n",
    "img_valid_balanced = []\n",
    "img_test_balanced = []\n",
    "imgs_train_pathsb = []\n",
    "imgs_valid_pathsb = []\n",
    "imgs_test_pathsb = []\n",
    "\n",
    "for img in glob.glob(\"C:/Users/etuna/Desktop/hw3/dataset/dataset/balanced/training_balanced/*\"):\n",
    "    n= cv2.imread(img)\n",
    "    img_train_balanced.append(n)\n",
    "    imgs_train_pathsb.append(img.split('\\\\')[1])\n",
    "for img in glob.glob(\"C:/Users/etuna/Desktop/hw3/dataset/dataset/balanced/valid_balanced/*\"):\n",
    "    n= cv2.imread(img)\n",
    "    imgs_valid_pathsb.append(img.split('\\\\')[1])\n",
    "    img_valid_balanced.append(n)\n",
    "for img in glob.glob(\"C:/Users/etuna/Desktop/hw3/dataset/dataset/balanced/test/*\"):\n",
    "    n= cv2.imread(img)\n",
    "    img_test_balanced.append(n)\n",
    "    imgs_test_pathsb.append(img.split('\\\\')[1])\n",
    "with open('C:/Users/etuna/Desktop/hw3/dataset/dataset/balanced/training_balanced_labels', 'r') as file:\n",
    "    labelStr = file.read().replace('\\n', '')\n",
    "    labels_train_balanced = list(map(int,labelStr))\n",
    "with open('C:/Users/etuna/Desktop/hw3/dataset/dataset/balanced/valid_balanced_labels', 'r') as file:\n",
    "    labelStr = file.read().replace('\\n', '')\n",
    "    labels_valid_balanced = list(map(int,labelStr))\n",
    "with open('C:/Users/etuna/Desktop/hw3/dataset/dataset/balanced/test_labels.txt', 'r') as file:\n",
    "    labelStr = file.read().replace('\\n', '')\n",
    "    labels_test = list(map(int,labelStr))\n",
    "\n",
    "print(str(len(img_train_balanced)))\n",
    "print(str(len(img_valid_balanced)))\n",
    "print(str(len(img_test_balanced)))\n",
    "print(imgs_train_pathsb)\n",
    "print(\"---\")\n",
    "print(imgs_valid_pathsb)\n",
    "print(\"---\")\n",
    "print(imgs_test_pathsb)\n",
    "print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cathedral-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "t_path = \"C:/Users/etuna/Desktop\\hw3/dataset/dataset/balanced_dir/\"\n",
    "## save to related dirs\n",
    "for i, img in enumerate(img_train_balanced):\n",
    "    if labels_train_balanced[i] == 1:\n",
    "        cv2.imwrite(t_path+\"train/1/\"+imgs_train_pathsb[i], img)\n",
    "    elif labels_train_balanced[i] == 2:\n",
    "        cv2.imwrite(t_path+\"train/2/\"+imgs_train_pathsb[i], img)\n",
    "    else:\n",
    "        cv2.imwrite(t_path+\"train/3/\"+imgs_train_pathsb[i], img)\n",
    "\n",
    "for i, img in enumerate(img_valid_balanced):\n",
    "    if labels_valid_balanced[i] == 1:\n",
    "        cv2.imwrite(t_path+\"valid/1/\"+imgs_valid_pathsb[i], img)\n",
    "    elif labels_valid_balanced[i] == 2:\n",
    "        cv2.imwrite(t_path+\"valid/2/\"+imgs_valid_pathsb[i], img)\n",
    "    else:\n",
    "        cv2.imwrite(t_path+\"valid/3/\"+imgs_valid_pathsb[i], img)\n",
    "        \n",
    "for i, img in enumerate(img_test_balanced):\n",
    "    if labels_test[i] == 1:\n",
    "        cv2.imwrite(t_path+\"test/1/\"+imgs_test_pathsb[i], img)\n",
    "    elif labels_test[i] == 2:\n",
    "        cv2.imwrite(t_path+\"test/2/\"+imgs_test_pathsb[i], img)\n",
    "    else:\n",
    "        cv2.imwrite(t_path+\"test/3/\"+imgs_test_pathsb[i], img)\n",
    "print(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "alone-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_valid_balanced[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "elder-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(image_datasets, model, b, optimizer,scheduler, num_epochs):\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size = 1, shuffle = True, num_workers = 4) for x in ['train', 'valid', 'test']}\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_no_corrects = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"epoch:\"+str(epoch))\n",
    "         # Set the model to the training mode for updating the weights using\n",
    "         # the first portion of training images\n",
    "        model.train()\n",
    "        \n",
    "        for inputs, labels in dataloaders['train']: # iterate over data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        # Set the model to the evaluation mode for selecting the best network\n",
    "        # based on the number of correctly classified validation images\n",
    "        model.eval()\n",
    "        best_no_corrects_training = 0\n",
    "        no_corrects_training = 0\n",
    "        no_samples_training = 0\n",
    "        correct_dict_training = {}\n",
    "        actual_dict_training = {}\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            no_samples_training += 1\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                no_corrects_training += torch.sum(preds == labels.data)\n",
    "                if preds == labels.data:\n",
    "                    if not preds.item() in correct_dict_training:\n",
    "                        correct_dict_training[labels.data.item()] = 1\n",
    "                    else:\n",
    "                        correct_dict_training[labels.data.item()] += 1\n",
    "                if not labels.data.item() in actual_dict_training:\n",
    "                    actual_dict_training[labels.data.item()] = 1\n",
    "                else:\n",
    "                    actual_dict_training[labels.data.item()] += 1\n",
    "        if no_corrects_training > best_no_corrects_training:\n",
    "            best_no_corrects_training = no_corrects_training\n",
    "        \n",
    "        no_corrects = 0\n",
    "        no_samples = 0\n",
    "        correct_dict = {}\n",
    "        actual_dict = {}\n",
    "        for inputs, labels in dataloaders['valid']:\n",
    "            no_samples += 1\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                no_corrects += torch.sum(preds == labels.data)\n",
    "                if preds == labels.data:\n",
    "                    if not preds.item() in correct_dict:\n",
    "                        correct_dict[labels.data.item()] = 1\n",
    "                    else:\n",
    "                        correct_dict[labels.data.item()] += 1\n",
    "                if not labels.data.item() in actual_dict:\n",
    "                    actual_dict[labels.data.item()] = 1\n",
    "                else:\n",
    "                    actual_dict[labels.data.item()] += 1\n",
    "        if no_corrects > best_no_corrects:\n",
    "            best_no_corrects = no_corrects\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        best_no_corrects_test = 0\n",
    "        no_corrects_test = 0\n",
    "        no_samples_test = 0\n",
    "        correct_dict_test = {}\n",
    "        actual_dict_test = {}\n",
    "        for inputs, labels in dataloaders['test']:\n",
    "            no_samples_test += 1\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                no_corrects_test += torch.sum(preds == labels.data)\n",
    "                if preds == labels.data:\n",
    "                    if not preds.item() in correct_dict_test:\n",
    "                        correct_dict_test[labels.data.item()] = 1\n",
    "                    else:\n",
    "                        correct_dict_test[labels.data.item()] += 1\n",
    "                if not labels.data.item() in actual_dict_test:\n",
    "                    actual_dict_test[labels.data.item()] = 1\n",
    "                else:\n",
    "                    actual_dict_test[labels.data.item()] += 1\n",
    "        if no_corrects_test > best_no_corrects_test:\n",
    "            best_no_corrects_test = no_corrects_test\n",
    "            #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        scheduler.step()\n",
    "     # Load the weights of the best network\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(\"Training -----------------------------------\")\n",
    "    print(\"Best no correct:\"+str(best_no_corrects_training.item()))   \n",
    "    print(\"Number of samples(valid):\"+str(no_samples_training))\n",
    "    print(\"Accuracy:\"+str(best_no_corrects_training / no_samples_training))\n",
    "    print(\"Accuracy on class 1:\"+str(correct_dict_training.get(1, 0)/actual_dict_training.get(1, 1)))\n",
    "    print(\"Accuracy on class 2:\"+str(correct_dict_training.get(2, 0)/actual_dict_training.get(2, 1)))\n",
    "    print(\"Accuracy on class 3:\"+str(correct_dict_training.get(3, 0)/actual_dict_training.get(3, 1)))\n",
    "    print(\"-------------\")\n",
    "    print(\"Validation -----------------------------------\")\n",
    "    print(\"Best no correct:\"+str(best_no_corrects.item()))   \n",
    "    print(\"Number of samples(valid):\"+str(no_samples))\n",
    "    print(\"Accuracy:\"+str(best_no_corrects / no_samples))\n",
    "    print(\"Accuracy on class 1:\"+str(correct_dict.get(1, 0)/actual_dict.get(1, 1)))\n",
    "    print(\"Accuracy on class 2:\"+str(correct_dict.get(2, 0)/actual_dict.get(2, 1)))\n",
    "    print(\"Accuracy on class 3:\"+str(correct_dict.get(3, 0)/actual_dict.get(3, 1)))\n",
    "    print(\"-------------\")\n",
    "    print(\"Test : \")\n",
    "    print(\"Best no correct:\"+str(best_no_corrects_test.item()))   \n",
    "    print(\"Number of samples(valid):\"+str(no_samples_test))\n",
    "    print(\"Accuracy:\"+str(best_no_corrects_test / no_samples_test))\n",
    "    print(\"Accuracy on class 1:\"+str(correct_dict_test.get(1, 0)/actual_dict_test.get(1, 1)))\n",
    "    print(\"Accuracy on class 2:\"+str(correct_dict_test.get(2, 0)/actual_dict_test.get(2, 1)))\n",
    "    print(\"Accuracy on class 3:\"+str(correct_dict_test.get(3, 0)/actual_dict_test.get(3, 1)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eleven-strength",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': Dataset ImageFolder\n",
      "    Number of datapoints: 150\n",
      "    Root location: C:/Users/etuna/Desktop/hw3/dataset/dataset/dir/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           ), 'valid': Dataset ImageFolder\n",
      "    Number of datapoints: 36\n",
      "    Root location: C:/Users/etuna/Desktop/hw3/dataset/dataset/dir/valid\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           ), 'test': Dataset ImageFolder\n",
      "    Number of datapoints: 144\n",
      "    Root location: C:/Users/etuna/Desktop/hw3/dataset/dataset/dir/test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )}\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'C:/Users/etuna/Desktop/hw3/dataset/dataset/dir/'\n",
    "data_transforms = {\n",
    " 'train': transforms.Compose([\n",
    " # put the input to Tensor format in order to use torch\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "     ]),\n",
    " 'valid': transforms.Compose([\n",
    " # put the input to Tensor format in order to use torch\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "     ]),\n",
    " 'test': transforms.Compose([\n",
    " # put the input to Tensor format in order to use torch\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "     ])\n",
    "}\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    " data_transforms[x]) for x in ['train', 'valid', 'test']}\n",
    "print(image_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "steady-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "epoch:1\n",
      "epoch:2\n",
      "epoch:3\n",
      "epoch:4\n",
      "epoch:5\n",
      "epoch:6\n",
      "epoch:7\n",
      "epoch:8\n",
      "epoch:9\n",
      "epoch:10\n",
      "epoch:11\n",
      "epoch:12\n",
      "epoch:13\n",
      "epoch:14\n",
      "epoch:15\n",
      "epoch:16\n",
      "epoch:17\n",
      "epoch:18\n",
      "epoch:19\n",
      "epoch:20\n",
      "epoch:21\n",
      "epoch:22\n",
      "epoch:23\n",
      "epoch:24\n",
      "epoch:25\n",
      "epoch:26\n",
      "epoch:27\n",
      "epoch:28\n",
      "epoch:29\n",
      "Training -----------------------------------\n",
      "Best no correct:149\n",
      "Number of samples(valid):150\n",
      "Accuracy:tensor(0.9933)\n",
      "Accuracy on class 1:1.0\n",
      "Accuracy on class 2:1.0\n",
      "Accuracy on class 3:0.0\n",
      "-------------\n",
      "Validation -----------------------------------\n",
      "Best no correct:28\n",
      "Number of samples(valid):36\n",
      "Accuracy:tensor(0.7778)\n",
      "Accuracy on class 1:1.0\n",
      "Accuracy on class 2:0.0\n",
      "Accuracy on class 3:0.0\n",
      "-------------\n",
      "Test : \n",
      "Best no correct:64\n",
      "Number of samples(valid):144\n",
      "Accuracy:tensor(0.4444)\n",
      "Accuracy on class 1:0.7719298245614035\n",
      "Accuracy on class 2:0.2564102564102564\n",
      "Accuracy on class 3:0.0\n"
     ]
    }
   ],
   "source": [
    "model = train_model(image_datasets=image_datasets,model= model_conv, b = 0, optimizer=optimizer_conv,scheduler=exp_lr_scheduler, num_epochs=30 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "applicable-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-fashion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
