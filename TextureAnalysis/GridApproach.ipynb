{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import math\n",
    "from libsvm.svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "immediate-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkCoords(rows, cols, fIx, fIy, sIx, sIy):\n",
    "    return fIx >= 0 and fIy >= 0 and fIx <= (rows - 1) and fIy <= (cols - 1) and sIx >= 0 and sIy >= 0 and sIx <= (rows - 1) and sIy <= (cols - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "searching-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "medieval-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCooccurrenceMatrix(grayImg, binNumber, di, dj):\n",
    "    rows, cols = grayImg.shape\n",
    "    bins = {}\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            fIx = r + di\n",
    "            fIy = c + dj\n",
    "            sIx = r + 1 + di\n",
    "            sIy = c + 1 + dj\n",
    "            if not checkCoords(rows, cols, fIx, fIy, sIx, sIy):\n",
    "                continue\n",
    "            fpx = grayImg[fIx][fIy]\n",
    "            spx = grayImg[sIx][sIy]\n",
    "            if (fpx, spx) in bins:\n",
    "                bins[(fpx, spx)] += 1\n",
    "            else:\n",
    "                bins[(fpx, spx)] = 1\n",
    "            \n",
    "    \n",
    "    arr2Img = np.zeros(shape = (256,256))\n",
    "    for key, val in bins.items():\n",
    "        arr2Img[key[0]][key[1]] = val\n",
    "    \n",
    "    im = Image.fromarray(np.uint8(arr2Img))\n",
    "    #plt.imshow(im)\n",
    "    #plt.show()\n",
    "    return arr2Img\n",
    "def calculateAccumulatedCooccurrenceMatrix(grayImg, binNumber, d):\n",
    "    dists = [(d, 0), (d, d), (0 , d), (-d, d), (-d, 0), (-d, -d), (0, -d), (d, -d)]\n",
    "    arr = np.zeros(shape=(256,256))\n",
    "    for d in dists:\n",
    "        arr += calculateCooccurrenceMatrix(grayImg, binNumber, d[0], d[1])\n",
    "    im = Image.fromarray(np.uint8(arr))\n",
    "    return arr\n",
    "def calculateCooccurrenceFeatures(accM):\n",
    "    accMNormalized = normalizeAccm(accM)\n",
    "    asm = angularSecondMoment(accMNormalized)\n",
    "    entr = entropy(accMNormalized)\n",
    "    cont = contrast(accMNormalized)\n",
    "    invDiff = inverseDiffMoment(accMNormalized)\n",
    "    maxProb = maxProbability(accMNormalized)\n",
    "    corr = correlation(accMNormalized)\n",
    "    return asm, entr, cont, invDiff, maxProb, corr\n",
    "def normalizeAccm(accM):\n",
    "    rows, cols = accM.shape\n",
    "    puv = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            puv += accM[r][c]\n",
    "    \n",
    "    if puv == 0:\n",
    "        puv = 1\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            accM[r][c] /= puv\n",
    "            #if accM[r][c] > 0:\n",
    "                #print(str(accM[r][c]))\n",
    "    im = Image.fromarray(np.uint8(accM))\n",
    "    #plt.imshow(im)\n",
    "    #plt.show()\n",
    "    return accM\n",
    "def angularSecondMoment(accMNorm):\n",
    "    rows, cols = accMNorm.shape\n",
    "    asm = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            asm += math.pow(accMNorm[r][c], 2)\n",
    "    return asm\n",
    "def entropy(accMNorm):\n",
    "    rows, cols = accMNorm.shape\n",
    "    entr = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if accMNorm[r][c] == 0:\n",
    "                continue\n",
    "            entr += accMNorm[r][c] * math.log(accMNorm[r][c])\n",
    "    return -entr\n",
    "def contrast(accMNorm):\n",
    "    rows, cols = accMNorm.shape\n",
    "    cont = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            cont += accMNorm[r][c] * (r-c)*(r-c)\n",
    "    return cont\n",
    "def inverseDiffMoment(accMNorm):\n",
    "    rows, cols = accMNorm.shape\n",
    "    idm = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            idm += accMNorm[r][c] / (1 + math.pow((r - c), 2))\n",
    "    return idm\n",
    "def maxProbability(accMNorm):\n",
    "    rows, cols = accMNorm.shape\n",
    "    maxProb = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if accMNorm[r][c] > maxProb:\n",
    "                maxProb = accMNorm[r][c]\n",
    "    return maxProb\n",
    "def correlation(accMNorm):\n",
    "    rows, cols = accMNorm.shape\n",
    "    Ux = []\n",
    "    Uy = []\n",
    "    for r in range(rows):\n",
    "        ux = 0\n",
    "        for c in range(cols):\n",
    "            ux += accMNorm[r][c]\n",
    "        Ux.append(ux)\n",
    "    for c in range(cols):\n",
    "        uy = 0\n",
    "        for r in range(rows):\n",
    "            uy += accMNorm[r][c]\n",
    "        Uy.append(uy)\n",
    "    \n",
    "    sigX = []\n",
    "    sigY = []\n",
    "    for r in range(rows):\n",
    "        sigx = 0\n",
    "        for c in range(cols):\n",
    "            sigx += math.pow((r - Ux[r]), 2)*accMNorm[r][c]\n",
    "        sigX.append(math.sqrt(sigx))\n",
    "    for c in range(cols):\n",
    "        sigy = 0\n",
    "        for r in range(rows):\n",
    "            sigy += math.pow((r - Uy[c]), 2)*accMNorm[r][c]\n",
    "        sigY.append(math.sqrt(sigy))\n",
    "    \n",
    "    \n",
    "    corr = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if sigX[r] == 0 or sigY[c] == 0:\n",
    "                continue\n",
    "            corr += ( (r-Ux[r]) / sigX[r] ) * ( (c-Uy[c]) / sigY[c] ) * accMNorm[r][c]\n",
    "    return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abandoned-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 186\n",
      "Test set size: 144\n",
      "Train Labels size: 186\n",
      "Train Labels size: 144\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "imgs_train = []\n",
    "imgs_test = []\n",
    "labels_train = []\n",
    "labels_test = []\n",
    "for img in glob.glob(\"C:/Users/etuna/Desktop/HW2/dataset/dataset/training/*\"):\n",
    "    n= cv2.imread(img)\n",
    "    imgs_train.append(n)\n",
    "    \n",
    "for img in glob.glob(\"C:/Users/etuna/Desktop/HW2/dataset/dataset/test/*\"):\n",
    "    n= cv2.imread(img)\n",
    "    imgs_test.append(n)\n",
    "    \n",
    "with open('C:/Users/etuna/Desktop/HW2/dataset/dataset/training_labels.txt', 'r') as file:\n",
    "    labelStr = file.read().replace('\\n', '')\n",
    "    labels_train = list(map(int,labelStr))\n",
    "    \n",
    "with open('C:/Users/etuna/Desktop/HW2/dataset/dataset/test_labels.txt', 'r') as file:\n",
    "    labelStr = file.read().replace('\\n', '')\n",
    "    labels_test = list(map(int,labelStr))\n",
    "    \n",
    "print(\"Train set size:\",len(imgs_train))\n",
    "print(\"Test set size:\",len(imgs_test))\n",
    "print(\"Train Labels size:\", len(labels_train))\n",
    "print(\"Train Labels size:\", len(labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "working-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(N,data):\n",
    "    feat_data = []\n",
    "    for i,img in enumerate(data):\n",
    "        print(\"Img :\",i)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        accM = calculateAccumulatedCooccurrenceMatrix(gray ,8, 10)\n",
    "        subimgs = getCroppedImages(N, accM)\n",
    "        A=0\n",
    "        B=0\n",
    "        C=0\n",
    "        D=0\n",
    "        E=0\n",
    "        F=0\n",
    "        for subim in subimgs:\n",
    "            a,b,c,d,e,f = calculateCooccurrenceFeatures(subim)\n",
    "            A += a\n",
    "            B += b\n",
    "            C += c\n",
    "            D += d\n",
    "            E += e\n",
    "            F += f\n",
    "        lenn = len(subimgs)\n",
    "        feat_data.append([A/lenn,B/lenn,C/lenn,D/lenn,E/lenn,F/lenn])\n",
    "    return feat_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legendary-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedImages(N,img):\n",
    "    imgs = []\n",
    "    rows, cols = img.shape\n",
    "    rPointer = 0\n",
    "    cPointer = 0\n",
    "    while not cPointer >= cols:\n",
    "        while not rPointer  >= rows:\n",
    "            im = img[rPointer:rPointer+4, cPointer:cPointer+4]\n",
    "            imgs.append(im)\n",
    "            rPointer += N\n",
    "        cPointer += N\n",
    "    return imgs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hungarian-firewall",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img : 0\n",
      "Img : 1\n",
      "Img : 2\n",
      "Img : 3\n",
      "Img : 4\n",
      "Img : 5\n",
      "Img : 6\n",
      "Img : 7\n",
      "Img : 8\n",
      "Img : 9\n",
      "Img : 10\n",
      "Img : 11\n",
      "Img : 12\n",
      "Img : 13\n",
      "Img : 14\n",
      "Img : 15\n",
      "Img : 16\n",
      "Img : 17\n",
      "Img : 18\n",
      "Img : 19\n",
      "Img : 20\n",
      "Img : 21\n",
      "Img : 22\n",
      "Img : 23\n",
      "Img : 24\n",
      "Img : 25\n",
      "Img : 26\n",
      "Img : 27\n",
      "Img : 28\n",
      "Img : 29\n",
      "Img : 30\n",
      "Img : 31\n",
      "Img : 32\n",
      "Img : 33\n",
      "Img : 34\n",
      "Img : 35\n",
      "Img : 36\n",
      "Img : 37\n",
      "Img : 38\n",
      "Img : 39\n",
      "Img : 40\n",
      "Img : 41\n",
      "Img : 42\n",
      "Img : 43\n",
      "Img : 44\n",
      "Img : 45\n",
      "Img : 46\n",
      "Img : 47\n",
      "Img : 48\n",
      "Img : 49\n",
      "Img : 50\n",
      "Img : 51\n",
      "Img : 52\n",
      "Img : 53\n",
      "Img : 54\n",
      "Img : 55\n",
      "Img : 56\n",
      "Img : 57\n",
      "Img : 58\n",
      "Img : 59\n",
      "Img : 60\n",
      "Img : 61\n",
      "Img : 62\n",
      "Img : 63\n",
      "Img : 64\n",
      "Img : 65\n",
      "Img : 66\n",
      "Img : 67\n",
      "Img : 68\n",
      "Img : 69\n",
      "Img : 70\n",
      "Img : 71\n",
      "Img : 72\n",
      "Img : 73\n",
      "Img : 74\n",
      "Img : 75\n",
      "Img : 76\n",
      "Img : 77\n",
      "Img : 78\n",
      "Img : 79\n",
      "Img : 80\n",
      "Img : 81\n",
      "Img : 82\n",
      "Img : 83\n",
      "Img : 84\n",
      "Img : 85\n",
      "Img : 86\n",
      "Img : 87\n",
      "Img : 88\n",
      "Img : 89\n",
      "Img : 90\n",
      "Img : 91\n",
      "Img : 92\n",
      "Img : 93\n",
      "Img : 94\n",
      "Img : 95\n",
      "Img : 96\n",
      "Img : 97\n",
      "Img : 98\n",
      "Img : 99\n",
      "Img : 100\n",
      "Img : 101\n",
      "Img : 102\n",
      "Img : 103\n",
      "Img : 104\n",
      "Img : 105\n",
      "Img : 106\n",
      "Img : 107\n",
      "Img : 108\n",
      "Img : 109\n",
      "Img : 110\n",
      "Img : 111\n",
      "Img : 112\n",
      "Img : 113\n",
      "Img : 114\n",
      "Img : 115\n",
      "Img : 116\n",
      "Img : 117\n",
      "Img : 118\n",
      "Img : 119\n",
      "Img : 120\n",
      "Img : 121\n",
      "Img : 122\n",
      "Img : 123\n",
      "Img : 124\n",
      "Img : 125\n",
      "Img : 126\n",
      "Img : 127\n",
      "Img : 128\n",
      "Img : 129\n",
      "Img : 130\n",
      "Img : 131\n",
      "Img : 132\n",
      "Img : 133\n",
      "Img : 134\n",
      "Img : 135\n",
      "Img : 136\n",
      "Img : 137\n",
      "Img : 138\n",
      "Img : 139\n",
      "Img : 140\n",
      "Img : 141\n",
      "Img : 142\n",
      "Img : 143\n",
      "Img : 144\n",
      "Img : 145\n",
      "Img : 146\n",
      "Img : 147\n",
      "Img : 148\n",
      "Img : 149\n",
      "Img : 150\n",
      "Img : 151\n",
      "Img : 152\n",
      "Img : 153\n",
      "Img : 154\n",
      "Img : 155\n",
      "Img : 156\n",
      "Img : 157\n",
      "Img : 158\n",
      "Img : 159\n",
      "Img : 160\n",
      "Img : 161\n",
      "Img : 162\n",
      "Img : 163\n",
      "Img : 164\n",
      "Img : 165\n",
      "Img : 166\n",
      "Img : 167\n",
      "Img : 168\n",
      "Img : 169\n",
      "Img : 170\n",
      "Img : 171\n",
      "Img : 172\n",
      "Img : 173\n",
      "Img : 174\n",
      "Img : 175\n",
      "Img : 176\n",
      "Img : 177\n",
      "Img : 178\n",
      "Img : 179\n",
      "Img : 180\n",
      "Img : 181\n",
      "Img : 182\n",
      "Img : 183\n",
      "Img : 184\n",
      "Img : 185\n",
      "Img : 0\n",
      "Img : 1\n",
      "Img : 2\n",
      "Img : 3\n",
      "Img : 4\n",
      "Img : 5\n",
      "Img : 6\n",
      "Img : 7\n",
      "Img : 8\n",
      "Img : 9\n",
      "Img : 10\n",
      "Img : 11\n",
      "Img : 12\n",
      "Img : 13\n",
      "Img : 14\n",
      "Img : 15\n",
      "Img : 16\n",
      "Img : 17\n",
      "Img : 18\n",
      "Img : 19\n",
      "Img : 20\n",
      "Img : 21\n",
      "Img : 22\n",
      "Img : 23\n",
      "Img : 24\n",
      "Img : 25\n",
      "Img : 26\n",
      "Img : 27\n",
      "Img : 28\n",
      "Img : 29\n",
      "Img : 30\n",
      "Img : 31\n",
      "Img : 32\n",
      "Img : 33\n",
      "Img : 34\n",
      "Img : 35\n",
      "Img : 36\n",
      "Img : 37\n",
      "Img : 38\n",
      "Img : 39\n",
      "Img : 40\n",
      "Img : 41\n",
      "Img : 42\n",
      "Img : 43\n",
      "Img : 44\n",
      "Img : 45\n",
      "Img : 46\n",
      "Img : 47\n",
      "Img : 48\n",
      "Img : 49\n",
      "Img : 50\n",
      "Img : 51\n",
      "Img : 52\n",
      "Img : 53\n",
      "Img : 54\n",
      "Img : 55\n",
      "Img : 56\n",
      "Img : 57\n",
      "Img : 58\n",
      "Img : 59\n",
      "Img : 60\n",
      "Img : 61\n",
      "Img : 62\n",
      "Img : 63\n",
      "Img : 64\n",
      "Img : 65\n",
      "Img : 66\n",
      "Img : 67\n",
      "Img : 68\n",
      "Img : 69\n",
      "Img : 70\n",
      "Img : 71\n",
      "Img : 72\n",
      "Img : 73\n",
      "Img : 74\n",
      "Img : 75\n",
      "Img : 76\n",
      "Img : 77\n",
      "Img : 78\n",
      "Img : 79\n",
      "Img : 80\n",
      "Img : 81\n",
      "Img : 82\n",
      "Img : 83\n",
      "Img : 84\n",
      "Img : 85\n",
      "Img : 86\n",
      "Img : 87\n",
      "Img : 88\n",
      "Img : 89\n",
      "Img : 90\n",
      "Img : 91\n",
      "Img : 92\n",
      "Img : 93\n",
      "Img : 94\n",
      "Img : 95\n",
      "Img : 96\n",
      "Img : 97\n",
      "Img : 98\n",
      "Img : 99\n",
      "Img : 100\n",
      "Img : 101\n",
      "Img : 102\n",
      "Img : 103\n",
      "Img : 104\n",
      "Img : 105\n",
      "Img : 106\n",
      "Img : 107\n",
      "Img : 108\n",
      "Img : 109\n",
      "Img : 110\n",
      "Img : 111\n",
      "Img : 112\n",
      "Img : 113\n",
      "Img : 114\n",
      "Img : 115\n",
      "Img : 116\n",
      "Img : 117\n",
      "Img : 118\n",
      "Img : 119\n",
      "Img : 120\n",
      "Img : 121\n",
      "Img : 122\n",
      "Img : 123\n",
      "Img : 124\n",
      "Img : 125\n",
      "Img : 126\n",
      "Img : 127\n",
      "Img : 128\n",
      "Img : 129\n",
      "Img : 130\n",
      "Img : 131\n",
      "Img : 132\n",
      "Img : 133\n",
      "Img : 134\n",
      "Img : 135\n",
      "Img : 136\n",
      "Img : 137\n",
      "Img : 138\n",
      "Img : 139\n",
      "Img : 140\n",
      "Img : 141\n",
      "Img : 142\n",
      "Img : 143\n",
      "Length of feat_train: 186\n",
      "Length of feat_test: 144\n"
     ]
    }
   ],
   "source": [
    "feat_train = prepareData(64,imgs_train)\n",
    "feat_test = prepareData(64,imgs_test)\n",
    "print(\"Length of feat_train:\", str(len(feat_train)))\n",
    "print(\"Length of feat_test:\", str(len(feat_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fifteen-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_train_temp = feat_train\n",
    "feat_test_temp = feat_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "prescription-planner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numerous-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceTrainingSets(data, labels):\n",
    "    mdata = normalizeFeatures(data)\n",
    "    label_dict = {}\n",
    "    for l in labels:\n",
    "        if l in label_dict:\n",
    "            label_dict[l] += 1\n",
    "        else:\n",
    "            label_dict[l] = 1\n",
    "    minEl = 9999\n",
    "    minLabel = -1\n",
    "    for k, v in label_dict.items():\n",
    "        if v < minEl:\n",
    "            minEl = v\n",
    "            minLabel=k\n",
    "            \n",
    "    for k, v in label_dict.items():\n",
    "        if k == minLabel:\n",
    "            label_dict[k] = minEl\n",
    "        else:\n",
    "            label_dict[k] = minEl + (label_dict[k]-minEl)/2\n",
    "\n",
    "    newData = []\n",
    "    newLabels = []\n",
    "    \n",
    "    for i, d in enumerate(mdata):\n",
    "        label= labels[i]\n",
    "        if label_dict[label] > 0:\n",
    "            newData.append(d)\n",
    "            newLabels.append(label)\n",
    "            label_dict[label] -= 1\n",
    "    return newData, newLabels\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dutch-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeFeatures(features):\n",
    "    #print(features)\n",
    "    mins = np.min(features, axis = 0)\n",
    "    maxs = np.max(features, axis = 0)\n",
    "    newFeatures = []\n",
    "    for i, f in enumerate(features):\n",
    "        mf = (f - mins)/(maxs-mins)\n",
    "        #print(f)\n",
    "        #print(mins)\n",
    "        #print(maxs)\n",
    "        #print(mf)\n",
    "        #print(\"\\n\\n\\n\")\n",
    "        newFeatures.append(mf)\n",
    "    #print(\"newfeats:\")\n",
    "    #print(newFeatures)\n",
    "    return features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "roman-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassAccuricies(result, actual):\n",
    "    correctDict = {}\n",
    "    for i, r in enumerate(result):\n",
    "        actVal = actual[i]\n",
    "        if actVal == r:\n",
    "            if actVal in correctDict:\n",
    "                correctDict[actVal] += 1\n",
    "            else:\n",
    "                correctDict[actVal] = 1\n",
    "\n",
    "    actualDict = {}\n",
    "    for a in actual:\n",
    "        if a in actualDict:\n",
    "            actualDict[a] += 1\n",
    "        else:\n",
    "            actualDict[a] = 1\n",
    "    mres = {}\n",
    "    for r in correctDict:\n",
    "        corr = correctDict[r]\n",
    "        act = actualDict[r]\n",
    "        mres[r] = (corr/act)\n",
    "        \n",
    "    return mres\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "numerical-function",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan],\n",
       " [nan, nan, nan, nan, 0.0, nan]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "corrected-bikini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 20.4301% (38/186) (classification)\n",
      "Accuracy = 27.0833% (39/144) (classification)\n",
      "Results : {3: 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-9ab7ec2dc06e>:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mf = (f - mins)/(maxs-mins)\n"
     ]
    }
   ],
   "source": [
    "feat_train_balanced, labels_training_balanced = balanceTrainingSets(feat_train, labels_train)\n",
    "prob = svm_problem(labels_training_balanced,feat_train_balanced)\n",
    "param = svm_parameter()\n",
    "param.C=1000\n",
    "param.kernel_type=LINEAR\n",
    "model = svm_train(prob, param)\n",
    "svm_save_model(\"LINEAR_C1_mdl\",model)\n",
    "result = svm_predict(labels_train, feat_train, model)\n",
    "result = svm_predict(labels_test, feat_test, model)\n",
    "mres=getClassAccuricies(result[0], labels_test)\n",
    "print(\"Results :\", mres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-pendant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-conjunction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-spirit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-innocent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-collector",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
